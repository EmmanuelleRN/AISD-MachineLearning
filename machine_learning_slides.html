<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>~</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <script src="libs/htmlwidgets/htmlwidgets.js"></script>
    <link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
    <script src="libs/datatables-binding/datatables.js"></script>
    <script src="libs/jquery/jquery-3.6.0.min.js"></script>
    <link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
    <link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
    <script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
    <link href="libs/crosstalk/css/crosstalk.min.css" rel="stylesheet" />
    <script src="libs/crosstalk/js/crosstalk.min.js"></script>
    <link rel="stylesheet" href="my_css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# ~
]

---


class: class: center, middle


&lt;!-- css: [default, duke-blue, hygge-duke] --&gt;

<div>
<style type="text/css">.xaringan-extra-logo {
width: 110px;
height: 128px;
z-index: 0;
background-image: url(www/channels4_profile-removebg-preview.png);
background-size: contain;
background-repeat: no-repeat;
position: absolute;
top:1em;right:1em;
}
</style>
<script>(function () {
  let tries = 0
  function addLogo () {
    if (typeof slideshow === 'undefined') {
      tries += 1
      if (tries < 10) {
        setTimeout(addLogo, 100)
      }
    } else {
      document.querySelectorAll('.remark-slide-content:not(.title-slide):not(.inverse):not(.hide_logo)')
        .forEach(function (slide) {
          const logo = document.createElement('div')
          logo.classList = 'xaringan-extra-logo'
          logo.href = null
          slide.appendChild(logo)
        })
    }
  }
  document.addEventListener('DOMContentLoaded', addLogo)
})()</script>
</div>



&lt;style type="text/css"&gt;
.regression table {
  font-size: 12px;     
}

.dataTables_info{
  font-size: 10px;
}

.dataTables_paginate{
  font-size: 10px;
}

.dataTables_length{
  font-size: 10px;
}
&lt;/style&gt;


# Machine Learning

---

# Machine Learning - Concepts

- Machine Learning (ML) is a subset of Artificial Intelligence (AI)
- Algorithms that can improve automatically through experience and by the use of data without being explicit programmed, reason why we say that the algorithms learn.
- With ML algorithms we can build a model to make predictions or decisions.
- Machine learning algorithms are used many different applications, for example:
  - Medicine
  - Email filtering
  - Speech recognition
  - Computer vision

&lt;center&gt;&lt;img src="https://backend.mile.cloud/upload/module/3ab28920802a8e64b800fdd2d22e7940.png" height="200"&gt;&lt;/img&gt;&lt;/center&gt;

---

class: center, middle
background-image: url(www/machine-learning.png)
background-size: contain

---

class: center, middle

# Supervised Learning

---

# Supervised Learning

.pull-left[
**Supervised learning** is where you have input variables ($X$) and an output variable ($y$) and you use an algorithm to learn the mapping function from the input to the output.

&lt;center&gt; y = f(X) &lt;/center&gt;

- It is the most common type of Machine Learning problem

- It is called **supervised** because we have the label that tell us the correct information, and we are going to be corrected if we predict wrong.

- Supervised learning can be grouped into two problems:
  - **Regression:** The output variable is a real number, for example, weight
  - **Clustering:** The output variable is a category, for example, disease and no disease 
]

.pull-right[
&lt;img src="https://maplearn.readthedocs.io/en/latest/_images/classif_reg.png"&gt;&lt;/img&gt;
]
---

# Steps

To solve this kind of problem we have some steps to follow:

1. Data collection
2. Exploratory Data Analysis (EDA)
3. Data Processing
4. Data Modelling

I am going to briefly explain each of these steps that will be clarified when we have the example.

---

# Data Collection

Data is very important for building a Machine learning model, as the model will learn from the dataset provided.

Collecting, **cleaning** and managing your data properly is a key factor for any ML project.

&lt;center&gt;&lt;p style="color:red"&gt;Garbage in, Garbage out&lt;/p&gt;&lt;/center&gt;

# Exploratory Data Analysis

Understand the characteristics and distribution of the data to help us understand what kind of model and what type of learning we are dealing with.

---

# Data Preprocessing

**Data preprocessing** is a process of cleaning the data and enabling them in the right format so they can be consumed by the algorithm it consists of data cleaning, missing values handling, feature selection and feature engineering 

If the dataset is not good and if there are missing values, outliers, or the features are not presented in a corrected format, the ML model built from this data will probably be bad. 

Methods usually used: encoding, normalization, imputation, outliers and NaN rejections, feature selection

## Encoding

**Encoding** is a method to transform the categorical data into numbers before using it to fit the model. For example, if we have the categories "cat" and "dog" we can encode them to 0 and 1.

---

## Feature scaling

Some ML models need to be on the "same range" to fit the data properly without the addition of bias due to different scales. For example, if we have as features height as 150cm and salary as 40000, salary might be more important due to potentially being in the 1000's but that's not necessarily true.

Methods:
- **Min-max normalization:** rescales the range of features to the new range in [0,1]
`$$X_{normalised} = \frac{X - min(X)}{max(X) - min(x)}$$`
- **Standardisation (Z-score normalisation):** Rescale the feature in a new range with a zero mean and a standard deviation is 1
`$$X_{normalised} = \frac{X - \bar{X}}{\sigma_X}$$`

---

## Missing values 

When we have missing data, the data won't be available, i.e., we have missing information. In this case we can:
- *Remove* the missing data
  - If enough data available
  - If the missing data does not have a pattern, i.e., is random
- *Inputation*: input the missing data using some statistical method
  - Use the mean or median of the variable to input missing values
  - Apply some algorithm, for example, linear or logistic regression to determine the likely value

## Feature selection

Select the most relevant variables for the model. This can be used to:
- Simplify the model
- Reduce overfitting
- Reduce training time

---

# Data Modelling

## Split the data

Before applying the model we need to make sure that we have a dataset to train and evaluate the model and another one to test the accuracy of the model.

We need to have different datasets to train and test the model because we want the model to learn and be able to **generalise on unseen data**. If we use the same dataset for training and testing, we are "leaking" information to the test and we can't garantee that the model can generalise. Also, having this split help us with problems like **overfitting** and **underfitting**.

The splits of the data usually are:
- Training
- Validation
- Testing

We usually split the data into 80% for training, 10% for validation and 10% for testing.

---

### Training set

It is the set of data that is used to train and make the model learn the hidden features/patterns in the data.

It should be large enough so that the model can “learn” correctly. Most of the data is used for training.

### Validation Set

This set is used to validate our model performance during training. This validation process gives information that helps us tune the model’s hyperparameters and configurations accordingly. 
- It tell us if the training is moving in the right direction or not.

The main idea of splitting the dataset into a validation set is to prevent our model from **overfitting** i.e., the model becomes really good at classifying the samples in the training set but cannot generalize and make accurate classifications on the data it has not seen before. 

### Test set

It tests the model after completing the training by providing an unbiased final model performance metric in terms of accuracy, precision, etc. 
- It answers the question: "How well does the model perform?"

---

## Modelling and evaluating the model

There are various machine learning models that you can choose according to the objective, for example, Linear Regression, Support Vector Machine (SVM), Decision Tree, Random Forest, K-Nearest Neighbors, Neural Network, K-means, etc.

We will see some of them when going through the examples.

Once we train the model, we need to evaluate it. Depending of your supervised learning problem, we have different metrics:
- **Classification metrics:** F1 score, precision, recall, accuracy
- **Regression metrics:** Mean Absolute Error, Mean Squared Error (MSE), Root Mean Square Error (RMSE), `\(R^2\)` metric.

## Prediction

When the best model is determined, it can be used to predict the new samples on the testing set.

---

class: center, middle

# Regression

---

# Regression

**Regression** is a type of **supervised** learning. One example of algorithm that we can use for this kid of problem is a **Linear Regression**.

- Yes, it is the same Linear Regression as previously seem
  -  In general, ML doesn’t make any assumptions but the user should make sure that the data meet the assumptions of the linear regression model if he/she wants to use it 
  
To explain how to solve a Regression problem, I am going to use the dataset *Medical insurance costs*. The data contains medical information and costs billed by health insurance companies. It contains 1338 rows of data and the  columns: age, gender, BMI, children, smoker, region as features and insurance charges as the label.

I am going to use the R libraries `tidyverse` and `tidymodels`. 
- `tidymodels` is a library for machine learning workflow

---

# Regression example - Data collection

The first step is to collect the data. The data is available at github and the link can be seen on the example.


```r
# Load libraries
library(tidyverse)
library(tidymodels)

# Load data sets
url &lt;- 'https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv'
insurance &lt;- read_csv(url)
```

We can see some of the data by using `glimpse`. We can see that we have 1338 rows and 7 columns. Also, `sex`, `smoker` and `region` are characters that will be transformed to factors.


```r
glimpse(insurance)
```

```
## Rows: 1,338
## Columns: 7
## $ age      &lt;dbl&gt; 19, 18, 28, 33, 32, 31, 46, 37, 37, 60, 25, 62, 23, 56, 27, 1…
## $ sex      &lt;chr&gt; "female", "male", "male", "male", "male", "female", "female",…
## $ bmi      &lt;dbl&gt; 27.900, 33.770, 33.000, 22.705, 28.880, 25.740, 33.440, 27.74…
## $ children &lt;dbl&gt; 0, 1, 3, 0, 0, 0, 1, 3, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0…
## $ smoker   &lt;chr&gt; "yes", "no", "no", "no", "no", "no", "no", "no", "no", "no", …
## $ region   &lt;chr&gt; "southwest", "southeast", "southeast", "northwest", "northwes…
## $ charges  &lt;dbl&gt; 16884.924, 1725.552, 4449.462, 21984.471, 3866.855, 3756.622,…
```

---

# Regression example - EDA

I'll be using the package `dlookr` to help us with the EDA. We are displaying:
- na: Number of NA values
- mean, standard deviation and IQR 
- p00: min value; p25: 1st quantile; p50: median; p75: third quantile; p100: max value


```r
library(dlookr)
library(DT)
dlookr::describe(insurance, quantiles = c(0, 0.25, 0.5, 0.75, 1),
                 statistics = c("na", "mean", "sd", "IQR", "quantiles")) %&gt;%
  DT::datatable(rownames = FALSE, options = list(dom = 't',scrollX = TRUE, scrollCollapse = TRUE)) %&gt;% formatRound(-1)
```

<div id="htmlwidget-8fd4d181699e8889ec4f" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-8fd4d181699e8889ec4f">{"x":{"filter":"none","vertical":false,"data":[["age","bmi","children","charges"],[1338,1338,1338,1338],[0,0,0,0],[39.2070254110613,30.6633968609865,1.0949177877429,13270.4222651413],[14.0499603792162,6.09818691167901,1.20549273978191,12110.011236694],[24,8.3975,2,11899.625365],[18,15.96,0,1121.8739],[27,26.29625,0,4740.28715],[39,30.4,1,9382.033],[51,34.69375,2,16639.912515],[64,53.13,5,63770.42801]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>described_variables<\/th>\n      <th>n<\/th>\n      <th>na<\/th>\n      <th>mean<\/th>\n      <th>sd<\/th>\n      <th>IQR<\/th>\n      <th>p00<\/th>\n      <th>p25<\/th>\n      <th>p50<\/th>\n      <th>p75<\/th>\n      <th>p100<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","scrollX":true,"scrollCollapse":true,"columnDefs":[{"targets":1,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":2,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":3,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":4,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":5,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":6,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":7,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":8,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":9,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":10,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"className":"dt-right","targets":[1,2,3,4,5,6,7,8,9,10]}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":["options.columnDefs.0.render","options.columnDefs.1.render","options.columnDefs.2.render","options.columnDefs.3.render","options.columnDefs.4.render","options.columnDefs.5.render","options.columnDefs.6.render","options.columnDefs.7.render","options.columnDefs.8.render","options.columnDefs.9.render"],"jsHooks":[]}</script>


---

# EDA - Sex


```r
insurance %&gt;% 
  group_by(sex) %&gt;% 
  describe(quantiles = c(0, 0.25, 0.5, 0.75, 1),
           statistics = c("mean", "sd", "IQR", "quantiles")) %&gt;%
  DT::datatable(rownames = FALSE, options = list(autoWidth = TRUE, dom = 't',scrollX = TRUE)) %&gt;% formatRound(-1)
```

<div id="htmlwidget-381e4a7ccfa36cb8ca23" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-381e4a7ccfa36cb8ca23">{"x":{"filter":"none","vertical":false,"data":[["age","age","bmi","bmi","charges","charges","children","children"],["female","male","female","male","female","male","female","male"],[662,676,662,676,662,676,662,676],[0,0,0,0,0,0,0,0],[39.5030211480363,38.9171597633136,30.377749244713,30.9431286982249,12569.5788438353,13956.7511777219,1.07401812688822,1.11538461538462],[14.054222528803,14.0501409481131,6.04602308574534,6.14043461579224,11128.7038009154,12971.0259150231,1.1921154944749,1.21898561350244],[24.75,25,8.18875,8.5825,9569.533125,14370.45625,2,2],[18,18,16.815,15.96,1607.5101,1121.8739,0,0],[27,26,26.125,26.41,4885.1587,4619.134,0,0],[40,39,30.1075,30.6875,9412.9625,9369.61575,1,1],[51.75,51,34.31375,34.9925,14454.691825,18989.59025,2,2],[64,64,48.07,53.13,63770.42801,62592.87309,5,5]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>described_variables<\/th>\n      <th>sex<\/th>\n      <th>n<\/th>\n      <th>na<\/th>\n      <th>mean<\/th>\n      <th>sd<\/th>\n      <th>IQR<\/th>\n      <th>p00<\/th>\n      <th>p25<\/th>\n      <th>p50<\/th>\n      <th>p75<\/th>\n      <th>p100<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"autoWidth":true,"dom":"t","scrollX":true,"columnDefs":[{"targets":1,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":2,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":3,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":4,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":5,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":6,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":7,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":8,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":9,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":10,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":11,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"className":"dt-right","targets":[2,3,4,5,6,7,8,9,10,11]}],"order":[],"orderClasses":false}},"evals":["options.columnDefs.0.render","options.columnDefs.1.render","options.columnDefs.2.render","options.columnDefs.3.render","options.columnDefs.4.render","options.columnDefs.5.render","options.columnDefs.6.render","options.columnDefs.7.render","options.columnDefs.8.render","options.columnDefs.9.render","options.columnDefs.10.render"],"jsHooks":[]}</script>

---

# EDA - Smoker


```r
insurance %&gt;% 
  group_by(smoker) %&gt;% 
  describe(quantiles = c(0, 0.25, 0.5, 0.75, 1),
           statistics = c("mean", "sd", "IQR", "quantiles")) %&gt;%
  DT::datatable(rownames = FALSE, options = list(autoWidth = TRUE, dom = 't',scrollX = TRUE, scrollY = "300px")) %&gt;% formatRound(-1)
```

<div id="htmlwidget-dcd290b9ff5e9a2d163d" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-dcd290b9ff5e9a2d163d">{"x":{"filter":"none","vertical":false,"data":[["age","age","bmi","bmi","charges","charges","children","children"],["no","yes","no","yes","no","yes","no","yes"],[1064,274,1064,274,1064,274,1064,274],[0,0,0,0,0,0,0,0],[39.3853383458647,38.514598540146,30.651795112782,30.7084489051095,8434.2682978562,32050.2318315328,1.09022556390977,1.11313868613139],[14.0834100168571,13.9231856073704,6.04311138978628,6.3186439826462,5993.78181919493,11541.5471755891,1.21813605659041,1.15706572915061],[25.25,22,8.115,9.11625,7376.44835,20192.9630625,2,2],[18,18,15.96,17.195,1121.8739,12829.4551,0,0],[26.75,27,26.315,26.08375,3986.4387,20826.2442125,0,0],[40,38,30.3525,30.4475,7345.4053,34456.34845,1,1],[52,49,34.43,35.2,11362.88705,41019.207275,2,2],[64,64,53.13,52.58,36910.60803,63770.42801,5,5]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>described_variables<\/th>\n      <th>smoker<\/th>\n      <th>n<\/th>\n      <th>na<\/th>\n      <th>mean<\/th>\n      <th>sd<\/th>\n      <th>IQR<\/th>\n      <th>p00<\/th>\n      <th>p25<\/th>\n      <th>p50<\/th>\n      <th>p75<\/th>\n      <th>p100<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"autoWidth":true,"dom":"t","scrollX":true,"scrollY":"300px","columnDefs":[{"targets":1,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":2,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":3,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":4,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":5,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":6,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":7,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":8,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":9,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":10,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":11,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"className":"dt-right","targets":[2,3,4,5,6,7,8,9,10,11]}],"order":[],"orderClasses":false}},"evals":["options.columnDefs.0.render","options.columnDefs.1.render","options.columnDefs.2.render","options.columnDefs.3.render","options.columnDefs.4.render","options.columnDefs.5.render","options.columnDefs.6.render","options.columnDefs.7.render","options.columnDefs.8.render","options.columnDefs.9.render","options.columnDefs.10.render"],"jsHooks":[]}</script>

---

# EDA - Region


```r
insurance %&gt;% 
  group_by(region) %&gt;% 
  describe(quantiles = c(0, 0.25, 0.5, 0.75, 1),
           statistics = c("mean", "sd", "IQR", "quantiles")) %&gt;%
  DT::datatable(rownames = FALSE, options = list(autoWidth = TRUE, scrollX = TRUE, scrollY = "300px")) %&gt;% formatRound(-1)
```

<div id="htmlwidget-7fa19047eea96281a232" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-7fa19047eea96281a232">{"x":{"filter":"none","vertical":false,"data":[["age","age","age","age","bmi","bmi","bmi","bmi","charges","charges","charges","charges","children","children","children","children"],["northeast","northwest","southeast","southwest","northeast","northwest","southeast","southwest","northeast","northwest","southeast","southwest","northeast","northwest","southeast","southwest"],[324,325,364,325,324,325,364,325,324,325,364,325,324,325,364,325],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[39.2685185185185,39.1969230769231,38.9395604395604,39.4553846153846,29.1735030864198,29.1997846153846,33.355989010989,30.5966153846154,13406.3845163858,12417.5753739692,14735.4114376099,12346.9373772923,1.0462962962963,1.14769230769231,1.04945054945055,1.14153846153846],[14.0690071612854,14.0516460222788,14.1645845492777,13.959885549617,5.93751330426977,5.13676496196331,6.47764793043144,5.69183579189187,11255.8030655785,11072.27692758,13971.0985889917,11557.1791007488,1.19894891474658,1.1718282239794,1.17727552370077,1.27595187267644],[24,25,24.25,24,8.0275,7.03,9.24,7.7,11493.0418125,9992.00725,15085.4007,8711.45,2,2,2,2],[18,19,18,19,15.96,17.385,19.8,17.4,1694.7964,1621.3402,1121.8739,1241.565,0,0,0,0],[27,26,26.75,27,24.86625,25.745,28.5725,26.9,5194.3222875,4719.73655,4440.8862,4751.07,0,0,0,0],[39.5,39,39,39,28.88,28.88,33.33,30.3,10057.652025,8965.79575,9294.13195,8798.593,1,1,1,1],[51,51,51,51,32.89375,32.775,37.8125,34.6,16687.3641,14711.7438,19526.2869,13462.52,2,2,2,2],[64,64,64,64,48.07,42.94,53.13,47.6,58571.07448,60021.39897,63770.42801,52590.82939,5,5,5,5]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>described_variables<\/th>\n      <th>region<\/th>\n      <th>n<\/th>\n      <th>na<\/th>\n      <th>mean<\/th>\n      <th>sd<\/th>\n      <th>IQR<\/th>\n      <th>p00<\/th>\n      <th>p25<\/th>\n      <th>p50<\/th>\n      <th>p75<\/th>\n      <th>p100<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"autoWidth":true,"scrollX":true,"scrollY":"300px","columnDefs":[{"targets":1,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":2,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":3,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":4,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":5,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":6,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":7,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":8,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":9,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":10,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"targets":11,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\", null);\n  }"},{"className":"dt-right","targets":[2,3,4,5,6,7,8,9,10,11]}],"order":[],"orderClasses":false}},"evals":["options.columnDefs.0.render","options.columnDefs.1.render","options.columnDefs.2.render","options.columnDefs.3.render","options.columnDefs.4.render","options.columnDefs.5.render","options.columnDefs.6.render","options.columnDefs.7.render","options.columnDefs.8.render","options.columnDefs.9.render","options.columnDefs.10.render"],"jsHooks":[]}</script>

---

# EDA - correlation


```r
correlate(insurance) %&gt;%
  plot()
```

![](machine_learning_slides_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

---

# Regression example - Feature engineering

We need to transform the characters values to factors.


```r
insurance &lt;- insurance %&gt;%
  mutate_if(is.character, as.factor)

glimpse(insurance)
```

```
## Rows: 1,338
## Columns: 7
## $ age      &lt;dbl&gt; 19, 18, 28, 33, 32, 31, 46, 37, 37, 60, 25, 62, 23, 56, 27, 1…
## $ sex      &lt;fct&gt; female, male, male, male, male, female, female, female, male,…
## $ bmi      &lt;dbl&gt; 27.900, 33.770, 33.000, 22.705, 28.880, 25.740, 33.440, 27.74…
## $ children &lt;dbl&gt; 0, 1, 3, 0, 0, 0, 1, 3, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0…
## $ smoker   &lt;fct&gt; yes, no, no, no, no, no, no, no, no, no, no, yes, no, no, yes…
## $ region   &lt;fct&gt; southwest, southeast, southeast, northwest, northwest, southe…
## $ charges  &lt;dbl&gt; 16884.924, 1725.552, 4449.462, 21984.471, 3866.855, 3756.622,…
```

Ordinary least squares is invariant to the scale of numerical variables, while methods such as lasso or ridge regression are not. 
- For invariant methods there is no real need for standardisation
- For non-invariant methods you should standardise. 

---

# Regression - Data Splitting

We will be using the `initial_split()` function to partition the data into training and test sets. The main arguments of the function are: `data` and `prop` that represents the training split proportion.
  - The split will be 80/20 for training/test.

After creating the partition, we need to apply the `training()` and `testing()` functions to have the partitions.

&gt; Remember to always use `set.seed()` to ensure your results are reproducible.


```r
set.seed(88)

# create split object
insurance_split &lt;- initial_split(insurance, prop = 0.8)

# Build training data set
insurance_train &lt;- insurance_split %&gt;% training()
cat("Insurance train dimension:", nrow(insurance_train), "rows and", ncol(insurance_train), "columns")
```

```
## Insurance train dimension: 1070 rows and 7 columns
```

```r
# Build testing data set
insurance_test &lt;- insurance_split %&gt;% testing()
cat("Insurance test dimension:", nrow(insurance_test), "rows and", ncol(insurance_test), "columns")
```

```
## Insurance test dimension: 268 rows and 7 columns
```

---

# Regression - Modelling

The next step in the process is to build a linear regression model to fit our training data.

For every model type, such as linear regression, there are numerous packages (or *engines*) that can be used.

For example, we can use the `lm()` function from base R or the `stan_glm()` function from the `rstanarm` package. Both of these functions will fit a linear regression model to our data with slightly different implementations.

The `parsnip` package from `tidymodels` acts like an aggregator across the various modeling engines within R. This makes it easy to implement machine learning algorithms from different R packages with one unifying syntax.

To specify a model object with parsnip, we must:

1. Pick a model type
2. Set the engine
3. Set the mode (either regression or classification)

---

# Regression - Modelling

Linear regression is implemented with the `linear_reg()` function in `parsnip`. To the set the engine and mode, we use `set_engine()` and `set_mode()`.

Let’s create a linear regression model object with the `lm` engine. 
- This is the default engine for most applications.


```r
lm_model &lt;- linear_reg() %&gt;% 
            set_engine('lm') %&gt;% # adds lm implementation of linear regression
            set_mode('regression')

# View object properties
lm_model
```

```
## Linear Regression Model Specification (regression)
## 
## Computational engine: lm
```

---

# Regression - Fit model to data

We can fit the model by using the `fit()` function from `parsnip`. The function has the following arguments:
- parnsip model 
- model formula
- data frame with the training data

In our formula, we have specified that `charges` is the response variable and age, sex, bmi, children, smoker and region are our predictor variables.


```r
lm_fit &lt;- lm_model %&gt;% 
          fit(charges ~ ., data = insurance_train)

# View lm_fit properties
lm_fit
```

```
## parsnip model object
## 
## 
## Call:
## stats::lm(formula = charges ~ ., data = data)
## 
## Coefficients:
##     (Intercept)              age          sexmale              bmi  
##        -12582.4            257.7           -271.9            359.6  
##        children        smokeryes  regionnorthwest  regionsoutheast  
##           484.0          23549.5           -527.8          -1131.8  
## regionsouthwest  
##         -1229.9
```

---

# Regression - Exploring the model

To obtain the results from our trained model in a data frame, we can use the `tidy()` and `glance()` functions from the `broom` package.

The `tidy()` function takes a linear regression object and returns a data frame of the estimated model coefficients and their associated F-statistics and p-values.


```r
library(broom)
tidy(lm_fit) # Data frame of estimated coefficients
```

```
## # A tibble: 9 × 5
##   term            estimate std.error statistic   p.value
##   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)      -12582.    1063.    -11.8   1.92e- 30
## 2 age                 258.      12.6    20.5   8.98e- 79
## 3 sexmale            -272.     354.     -0.769 4.42e-  1
## 4 bmi                 360.      30.9    11.7   1.26e- 29
## 5 children            484.     145.      3.33  9.06e-  4
## 6 smokeryes         23550.     434.     54.2   4.35e-308
## 7 regionnorthwest    -528.     508.     -1.04  2.99e-  1
## 8 regionsoutheast   -1132.     504.     -2.24  2.50e-  2
## 9 regionsouthwest   -1230.     502.     -2.45  1.45e-  2
```

---

# Regression - Exploring the model

The `glance()` function returns performance metrics obtained on the training data such as the R2 value (r.squared) and the RMSE (sigma).


```r
# Performance metrics on training data
glance(lm_fit)
```

```
## # A tibble: 1 × 12
##   r.squared adj.r.squared sigma statistic p.value    df  logLik    AIC    BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.769         0.767 5755.      441.       0     8 -10778. 21575. 21625.
## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;
```

---

# Regression - Predict on the test set

To assess the performance of the model, we must use the test set to predict the charge value and then compare to the real value.

This is done with the `predict()` function. This function takes two important arguments:
- Trained model 
- new_data to generate predictions

It’s best to combine the test data set and the predictions into a single data frame.


```r
insurance_test_results &lt;- predict(lm_fit, new_data = insurance_test) %&gt;% 
                            bind_cols(insurance_test)

# View results
insurance_test_results %&gt;% head()
```

```
## # A tibble: 6 × 8
##    .pred   age sex      bmi children smoker region    charges
##    &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;       &lt;dbl&gt;
## 1  3285.    33 male    22.7        0 no     northwest  21984.
## 2  3529.    31 female  25.7        0 no     southeast   3757.
## 3 11641.    60 female  25.8        0 no     northwest  28923.
## 4 31690.    34 female  31.9        1 yes    northeast  37702.
## 5  1518.    18 female  26.3        0 no     northeast   2198.
## 6  8413.    31 female  36.6        2 no     southeast   4950.
```

---

# Regression - Evaluate the model

To evaluate the model, I'll use RMSE and `\(R^2\)` that can be obtained by using the functions `rmse()` and `rsq()` functions. Both functions take the following arguments:
- `data`: dataframe with real and predicted values
- `truth`: column with the real labels
- `estimate`: columns with the predictions


```r
# RMSE on test set
rmse(insurance_test_results, truth = charges, estimate = .pred) %&gt;%
  # R2 on the test set
  bind_rows(rsq(insurance_test_results, truth = charges, estimate = .pred))
```

```
## # A tibble: 2 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard    7185.   
## 2 rsq     standard       0.695
```

The closes to zero the RMSE value is the best your model is, and we can see that the RMSE of this model is very high, which indicates that this model is not a very good model to predict insurance charges.

---

# Regression - Plot R2

.pull-left[

We can visualise the fit of the model by plotting the `\(R^2\)`.


```r
ggplot(data = insurance_test_results,
       mapping = aes(x = .pred, y = charges)) +
  geom_point(color = '#006EA1') +
  geom_abline(intercept = 0, 
              slope = 1, 
              color = 'orange') +
  labs(title = 'Linear Regression Results - 
       Insurance Test Set',
       x = 'Predicted Insurance Value',
       y = 'Actual Insurance Value')
```
]

.pull-right[
![](machine_learning_slides_files/figure-html/unnamed-chunk-19-1.png)&lt;!-- --&gt;
]

---

class: center, middle

# Classification

---

# Classification

**Classification** is a type of **supervised** learning where we categorise data into classes. There are many different algorithms that can help us solve this kind of problems.

Classification requires a training dataset with many examples of inputs and outputs from which to learn. It can be categorised in two types of problems:
  - **Binary classification:** The outcome has only **two** labels, for example, disease and not disease. 
    - Some popular algorithms are: Logistic Regression, Decision Tree, K-Nearest Neighbour (KNN)
  - **Multi-label classification:** The outcome has multiple labels, for example, dog, cat, bird and other.
    - Some popular algorithms: KNN, Decision Tree, Random Forest, Naive Bayes

To evaluate the model performance we can make use of ROC, confusion matrix, etc. We need to be aware of **class imbalance** problems.


---

# Evaluation metrics

.pull-left[
When thinking about classification, some common metrics to understand performance involves:
  - Accuracy
  - Precision
  - Recall
  - ROC
  
Most of this metrics can be determined by creating a **confusion matrix**, a contingency table with two dimensions (*actual* and *predicted*) that help us determine the performance of a classification model when we know the true classification of the data.
]

.pull-right[

&lt;img src="https://www.nbshare.io/static/snapshots/cm_colored_1-min.png"&gt;&lt;/img&gt;

]

---

# Evaluation metrics - Confusion Matrix

From the confusion matrix, we can get the following performance metrics:

- **Accuracy:** Proportion of correct predictions among the total number of cases examined.
`$$\text{Acc} = \frac{TP + TN}{N + P}$$`
- **Precision or Positive Predictive Value (PPV):** Proportion of positive predictions that was actually correct
`$$\text{Pr} = \frac{TP}{TP + FP}$$`

- **Sensitivity or recall or True Positive Rate (TPR):** Proportion of correct predictions among the positive instances.
`$$\text{Recall} = \frac{TP}{TP + FN}$$`
- **F1 Score:** Harmonic mean of precision and recall.
`$$F_1 = \frac{2 \times TP}{2 \times TP + FP + FN}$$`

---

# Evaluation metric - ROC curve

.pull-left[

**ROC curve** is a performance measurement for the classification problems at various threshold settings. This curve plots two parameters:
- True Positive Rate
- False Positive Rate = 1 - Specificity

From the ROC curve we can get the **Area Under the Curve (AUC)** metric that ranges from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0.
- When AUC is 0.5, it means the model has no class separation capacity whatsoever. 

]

.pull-right[

&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Roc_curve.svg/2048px-Roc_curve.svg.png"&gt;&lt;/img&gt;

]

---

# Class Imbalance problem

An **imbalanced classification** problem is a problem where the distribution of examples across the known classes is biased or skewed. 
- The distribution can vary from a slight bias to a severe imbalance.

Most of the machine learning algorithms used for classification were designed around the assumption of an equal number of examples for each class. 
- This results in models that have poor predictive performance, specifically for the minority class
- Typically, the minority class is more important

For example, we want to detect fraudulent transaction, and if every 1000 transactions only 1 is fraudulent, it is very easy for the model to classify everything as non-fraud, so the accuracy of the model will be almost 1, but the actual class that we wanted to determine, it was wrongfully classified.
  - We need to look at other metrics that can tell us how the prediction performed for different classes
  
&gt; Using **accuracy** as a peformance metric is **not recommended**.

We need to use techniques that will help us undersampling the majority class or oversampling the minority class, for example, Random undersampling and SMOTE oversampling.

---

# Classification - Example

The dataset we are going to use to perform the classification problem is `BreastCancer: Wisconsin Breast Cancer Database`. The data can be downloaded from the `mlbench` package.

The data has 699 observations on 11 variables, one being a character variable, 9 being ordered or nominal, and 1 target class.


```r
library(mlbench)
data(BreastCancer)
BreastCancer &lt;- BreastCancer %&gt;% select(-Id)
glimpse(BreastCancer)
```

```
## Rows: 699
## Columns: 10
## $ Cl.thickness    &lt;ord&gt; 5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, …
## $ Cell.size       &lt;ord&gt; 1, 4, 1, 8, 1, 10, 1, 1, 1, 2, 1, 1, 3, 1, 7, 4, 1, 1,…
## $ Cell.shape      &lt;ord&gt; 1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1,…
## $ Marg.adhesion   &lt;ord&gt; 1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1,…
## $ Epith.c.size    &lt;ord&gt; 2, 7, 2, 3, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 7, 6, 2, 2, …
## $ Bare.nuclei     &lt;fct&gt; 1, 10, 2, 4, 1, 10, 10, 1, 1, 1, 1, 1, 3, 3, 9, 1, 1, …
## $ Bl.cromatin     &lt;fct&gt; 3, 3, 3, 3, 3, 9, 3, 3, 1, 2, 3, 2, 4, 3, 5, 4, 2, 3, …
## $ Normal.nucleoli &lt;fct&gt; 1, 2, 1, 7, 1, 7, 1, 1, 1, 1, 1, 1, 4, 1, 5, 3, 1, 1, …
## $ Mitoses         &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 4, 1, 1, 1, …
## $ Class           &lt;fct&gt; benign, benign, benign, benign, benign, malignant, ben…
```

---

# Classification example - Summary


```r
summary(BreastCancer)
```

```
##   Cl.thickness   Cell.size     Cell.shape  Marg.adhesion  Epith.c.size
##  1      :145   1      :384   1      :353   1      :407   2      :386  
##  5      :130   10     : 67   2      : 59   2      : 58   3      : 72  
##  3      :108   3      : 52   10     : 58   3      : 58   4      : 48  
##  4      : 80   2      : 45   3      : 56   10     : 55   1      : 47  
##  10     : 69   4      : 40   4      : 44   4      : 33   6      : 41  
##  2      : 50   5      : 30   5      : 34   8      : 25   5      : 39  
##  (Other):117   (Other): 81   (Other): 95   (Other): 63   (Other): 66  
##   Bare.nuclei   Bl.cromatin  Normal.nucleoli    Mitoses          Class    
##  1      :402   2      :166   1      :443     1      :579   benign   :458  
##  10     :132   3      :165   10     : 61     2      : 35   malignant:241  
##  2      : 30   1      :152   3      : 44     3      : 33                  
##  5      : 30   7      : 73   2      : 36     10     : 14                  
##  3      : 28   4      : 40   8      : 24     4      : 12                  
##  (Other): 61   5      : 34   6      : 22     7      :  9                  
##  NA's   : 16   (Other): 69   (Other): 69     (Other): 17
```

```r
BreastCancer %&gt;% group_by(Class) %&gt;% count() %&gt;% ungroup() %&gt;% mutate(prop = n / sum(n))
```

```
## # A tibble: 2 × 3
##   Class         n  prop
##   &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt;
## 1 benign      458 0.655
## 2 malignant   241 0.345
```

---

# Classification - Data Preprocessing

As we have missing data, we will drop the rows that are incomplete.


```r
BreastCancer %&gt;% anyNA()
```

```
## [1] TRUE
```

```r
cat("Number of rows before dropping missing values: ", nrow(BreastCancer))
```

```
## Number of rows before dropping missing values:  699
```

```r
BreastCancer &lt;- BreastCancer %&gt;% drop_na()
cat("Number of rows after dropping missing values: ", nrow(BreastCancer))
```

```
## Number of rows after dropping missing values:  683
```


As all the variables of the dataset, except Class, can be numerical features, I'll change the variable type.


```r
BreastCancer &lt;- BreastCancer %&gt;% 
  mutate_at(vars(-("Class")), as.numeric)
```

---

# Classification - Data Splitting

The split will be 80/20 for training/test.


```r
set.seed(88)

# create split object
bcancer_split &lt;- initial_split(BreastCancer, prop = 0.8)

# Build training data set
bcancer_train &lt;- bcancer_split %&gt;% training()
cat("Breast cancer train dimension:", nrow(bcancer_train), "rows and", ncol(bcancer_train), "columns")
```

```
## Breast cancer train dimension: 546 rows and 10 columns
```

```r
# Build testing data set
bcancer_test &lt;- bcancer_split %&gt;% testing()
cat("Breast cancer test dimension:", nrow(bcancer_test), "rows and", ncol(bcancer_test), "columns")
```

```
## Breast cancer test dimension: 137 rows and 10 columns
```

---

# Classification - Modelling

I will be using and comparing the results of two models:
  - Decision Tree
  - Suport Vector Machine (SVM)

.pull-left[
&lt;img src="https://www.tutorialandexample.com/wp-content/uploads/2019/10/Decision-Trees-Root-Node.png"&gt;&lt;/img&gt;
]

.pull-right[
&lt;img src="https://miro.medium.com/max/1088/1*6U9NrruycDBsPOyivpn8UQ.png" height="300"&gt;&lt;/img&gt;
]

---

# Classification - Modelling

Decision Tree and SVM are implemented with the  `decision_tree()` and `svm_linear()` functions in `parsnip`. To the set the engine and mode, we use `set_engine()` and `set_mode()`.

Let’s create this models using the following engines:
- `rpart` for the decision tree that needs the `rpart` package installed
- `LiblineaR` for the SVM that needs to have the package `LiblineaR` installed


```r
tree_model &lt;- decision_tree() %&gt;%
              set_engine('rpart') %&gt;%
              set_mode('classification')

svm_model &lt;- svm_linear() %&gt;%
             set_engine('LiblineaR') %&gt;%
             set_mode('classification')
```

---

# Classification - Fit model to data

`Class` is the response variable and all the other variables are our predictor variables.


```r
tree_fit &lt;- tree_model %&gt;% fit(Class ~ ., data = bcancer_train)
svm_fit &lt;- svm_model %&gt;% fit(Class ~ ., data = bcancer_train)

# View fit properties
svm_fit %&gt;% broom::tidy()
```

```
## # A tibble: 10 × 2
##    term            estimate
##    &lt;chr&gt;              &lt;dbl&gt;
##  1 Cl.thickness     -0.124 
##  2 Cell.size        -0.0537
##  3 Cell.shape       -0.0611
##  4 Marg.adhesion    -0.0494
##  5 Epith.c.size      0.0217
##  6 Bare.nuclei      -0.136 
##  7 Bl.cromatin      -0.104 
##  8 Normal.nucleoli  -0.0392
##  9 Mitoses          -0.136 
## 10 Bias              2.37
```

---

# Classification - Predict on the test set

To assess the performance of the model, we must use the test set to predict the charge value and then compare to the real value.



```r
bcancer_test_results_tree &lt;- predict(tree_fit, new_data = bcancer_test) %&gt;% 
                             bind_cols(bcancer_test)
bcancer_test_results_tree %&gt;% head(2)
```

```
## # A tibble: 2 × 11
##   .pred_class Cl.thickness Cell.size Cell.shape Marg.adhesion Epith.c.size
##   &lt;fct&gt;              &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;
## 1 benign                 3         1          1             1            2
## 2 malignant              8        10         10             8            7
## # … with 5 more variables: Bare.nuclei &lt;dbl&gt;, Bl.cromatin &lt;dbl&gt;,
## #   Normal.nucleoli &lt;dbl&gt;, Mitoses &lt;dbl&gt;, Class &lt;fct&gt;
```

```r
bcancer_test_results_svm &lt;- predict(svm_fit, new_data = bcancer_test) %&gt;% 
                            bind_cols(bcancer_test)
bcancer_test_results_svm %&gt;% head(2)                                      
```

```
## # A tibble: 2 × 11
##   .pred_class Cl.thickness Cell.size Cell.shape Marg.adhesion Epith.c.size
##   &lt;fct&gt;              &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;
## 1 benign                 3         1          1             1            2
## 2 malignant              8        10         10             8            7
## # … with 5 more variables: Bare.nuclei &lt;dbl&gt;, Bl.cromatin &lt;dbl&gt;,
## #   Normal.nucleoli &lt;dbl&gt;, Mitoses &lt;dbl&gt;, Class &lt;fct&gt;
```

---

# Classification - Evaluate the models

To evaluate the models, we will use the `confusionMatrix` function from `caret`.

.pull-left[
- Decision Tree

```r
library(caret)
confusionMatrix(bcancer_test_results_tree$.pred_class,
                bcancer_test_results_tree$Class) %&gt;% 
  tidy() %&gt;%
  filter(term %in% c("precision", "recall", "specificity", "f1", "accuracy")) %&gt;% 
  select(term, class, estimate)
```

```
## # A tibble: 5 × 3
##   term        class  estimate
##   &lt;chr&gt;       &lt;chr&gt;     &lt;dbl&gt;
## 1 accuracy    &lt;NA&gt;      0.949
## 2 specificity benign    0.952
## 3 precision   benign    0.978
## 4 recall      benign    0.947
## 5 f1          benign    0.963
```
]

.pull-right[
- SVM

```r
confusionMatrix(bcancer_test_results_svm$.pred_class,
                       bcancer_test_results_svm$Class) %&gt;% 
  tidy() %&gt;%
  filter(term %in% c("precision", "recall", "specificity", "f1", "accuracy")) %&gt;% 
  select(term, class, estimate)
```

```
## # A tibble: 5 × 3
##   term        class  estimate
##   &lt;chr&gt;       &lt;chr&gt;     &lt;dbl&gt;
## 1 accuracy    &lt;NA&gt;      0.956
## 2 specificity benign    0.905
## 3 precision   benign    0.959
## 4 recall      benign    0.979
## 5 f1          benign    0.969
```

]

---

class: center, middle

# Unsupervised Learning

---

# Unsupervised Learning

.pull-left[

This type of problem is called **Unsupervised** because, unlike supervised learning, we don't have a label.
- The algorithm learns patterns from unlabeled data. 

Common tasks:
- **Clustering:** Technique that groups unlabeled data based on their similarities or differences. 
  - Example: KMeans
- **Dimensionality Reduction**: Reduce the number of features while also preserving the integrity of the dataset as much as possible. 
  - Example: Principla Components Analysis (PCA)
  
Some challenges can occur when it allows machine learning models to execute without any human intervention. For example:
- Computational complexity due to a high volume of training data
- Longer training times
- Higher risk of inaccurate results
]

.pull-right[
&lt;img src="https://miro.medium.com/max/433/1*Iihw0V-r0raMMtcDTFGGQA.png"&gt;&lt;/img&gt;

]

---

class: center, middle

# Clustering

---

# Clustering

Clustering can be considered the most important unsupervised learning problem.

It involves discovering groups in data. Unlike supervised learning, clustering algorithms only interpret the input data and find natural groups or clusters in feature space.

A cluster is a collection of objects which are *similar* between them and are *dissimilar* to the objects belonging to other clusters.

Given a set of points, with some distance between points, grouping the points into some number of clusters, such that
- **internal (within the cluster)** distances should be small i.e members of clusters are close/similar to each other.
- **external (intra-cluster)** distances should be large i.e. members of different clusters are dissimilar.

---

# Distance metrics

We need to define a **distance** or **proximity** metric for 2 points.
- How similar or dissimilar 2 points are

- **Similarity `\(s(x_i, x_k)\)`**: Large if `\(x_i, x_k\)` are similar
- **Dissimilarity (or distance) `\(d(x_i, x_k)\)`**: Small if `\(x_i, x_k\)` are similar

Examples:

- **Euclidean Distance: ** `\(d(\textbf{p}, \textbf{q}) = \sqrt{\sum_{i=1}^n (p_i-q_i)^2}\)`

- **Mahalanobis Distance: ** `\(d_M(\textbf{p}, \textbf{q}) = \sqrt{(\textbf{p}-\textbf{y})^TS^{-1}(\textbf{p}-\textbf{y})}\)`

- **Jaccard Distance: ** `\(J(A, B) = \frac{|A \cap B|}{|A \cup B|} = \frac{|A \cap B|}{|A| + |B| - |A \cap B|}\)`

A *good* proximity measure is **very** application dependent. 

---

# Clustering - Example

The steps to perform an unsupervised learning task are very similar to an supervised one, with the difference that we don't need to predict anything.

For the example, we will use the the built-in R data set `USArrests`, which contains statistics in arrests per 100,000 residents for assault, murder, and rape in each of the 50 US states in 1973. It includes also the percent of the population living in urban areas.


```r
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms &amp; visualization

us_arrests &lt;- USArrests
glimpse(us_arrests)
```

```
## Rows: 50
## Columns: 4
## $ Murder   &lt;dbl&gt; 13.2, 10.0, 8.1, 8.8, 9.0, 7.9, 3.3, 5.9, 15.4, 17.4, 5.3, 2.…
## $ Assault  &lt;int&gt; 236, 263, 294, 190, 276, 204, 110, 238, 335, 211, 46, 120, 24…
## $ UrbanPop &lt;int&gt; 58, 48, 80, 50, 91, 78, 77, 72, 80, 60, 83, 54, 83, 65, 57, 6…
## $ Rape     &lt;dbl&gt; 21.2, 44.5, 31.0, 19.5, 40.6, 38.7, 11.1, 15.8, 31.9, 25.8, 2…
```

---

# Clustering - Data Preprocessing

We are going to check and remove NA's if the exist in the data


```r
us_arrests %&gt;% anyNA()
```

```
## [1] FALSE
```

As we don’t want the clustering algorithm to depend to an arbitrary variable unit, we start by scaling/standardizing the data using the R function `scale`:


```r
us_arrests_scaled &lt;- us_arrests %&gt;%
  scale()

head(us_arrests_scaled)
```

```
##                Murder   Assault   UrbanPop         Rape
## Alabama    1.24256408 0.7828393 -0.5209066 -0.003416473
## Alaska     0.50786248 1.1068225 -1.2117642  2.484202941
## Arizona    0.07163341 1.4788032  0.9989801  1.042878388
## Arkansas   0.23234938 0.2308680 -1.0735927 -0.184916602
## California 0.27826823 1.2628144  1.7589234  2.067820292
## Colorado   0.02571456 0.3988593  0.8608085  1.864967207
```

---

# Clustering - Distance

We can compute and visualise the distance matrix using the functions `get_dist` and `fviz_dist` from the `factoextra` package. 

- `get_dist:` Computing a distance matrix between the rows of a data matrix. 
  - The default distance computed is the **Euclidean**
- `fviz_dist:` Visualise the distance matrix


```r
distance &lt;- get_dist(us_arrests_scaled)
fviz_dist(distance)
```

![](machine_learning_slides_files/figure-html/unnamed-chunk-33-1.png)&lt;!-- --&gt;

---

# Clustering - K-Means

**K-means clustering** is the most commonly used unsupervised machine learning algorithm for partitioning a given data set into a set of `\(k\)` groups determine by the analyst. In k-means clustering, each cluster is represented by its center (i.e, centroid) which corresponds to the mean of points assigned to the cluster.

## Determining the optimal number of clusters

As the number of clusters is user specified, we would like to use the optimal number of clusters. The three most popular methods for determining the optimal clusters are:

- **Elbow method: ** Minimise the total intra-cluster variation (known as total within-cluster variation or total within-cluster sum of square)
  - Can be calculated using the function `fviz_nbclust` using method `wss`
- **Silhouette method: ** Measures the quality of a clustering, i.e., it determines how well each object lies within its cluster. A high average silhouette width indicates a good clustering.
  - Can be calculated using the function `fviz_nbclust` using method `silhouette`
- **Gap statistic: ** The approach can be applied to any clustering method. The gap statistic compares the total intracluster variation for different values of k with their expected values under null reference distribution of the data (i.e. a distribution with no obvious clustering).
  - Can be visulaised using the function `fviz_gap_stat` using the statistic generated by `clusGap`

---

# Clustering - Optimal number of clusters


```r
library(patchwork)

set.seed(123)

elbow_method &lt;- fviz_nbclust(us_arrests_scaled, kmeans, method = "wss")
sill &lt;- fviz_nbclust(us_arrests_scaled, kmeans, method = "silhouette")
gap_stat &lt;- clusGap(us_arrests_scaled, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
gap_plot &lt;- fviz_gap_stat(gap_stat)

elbow_method + sill + gap_plot
```

![](machine_learning_slides_files/figure-html/unnamed-chunk-34-1.png)&lt;!-- --&gt;


---

# Clustering - KMeans

With most of these approaches suggesting 3 as the number of optimal clusters, we can perform the final analysis and extract the results using 3 clusters.


```r
# Compute k-means clustering with k = 3
set.seed(123)
kmeans &lt;- kmeans(us_arrests_scaled, 3, nstart = 25)
print(kmeans)
```

```
## K-means clustering with 3 clusters of sizes 20, 13, 17
## 
## Cluster means:
##       Murder    Assault   UrbanPop       Rape
## 1  1.0049340  1.0138274  0.1975853  0.8469650
## 2 -0.9615407 -1.1066010 -0.9301069 -0.9667633
## 3 -0.4469795 -0.3465138  0.4788049 -0.2571398
## 
## Clustering vector:
##        Alabama         Alaska        Arizona       Arkansas     California 
##              1              1              1              3              1 
##       Colorado    Connecticut       Delaware        Florida        Georgia 
##              1              3              3              1              1 
##         Hawaii          Idaho       Illinois        Indiana           Iowa 
##              3              2              1              3              2 
##         Kansas       Kentucky      Louisiana          Maine       Maryland 
##              3              2              1              2              1 
##  Massachusetts       Michigan      Minnesota    Mississippi       Missouri 
##              3              1              2              1              1 
##        Montana       Nebraska         Nevada  New Hampshire     New Jersey 
##              2              2              1              2              3 
##     New Mexico       New York North Carolina   North Dakota           Ohio 
##              1              1              1              2              3 
##       Oklahoma         Oregon   Pennsylvania   Rhode Island South Carolina 
##              3              3              3              3              1 
##   South Dakota      Tennessee          Texas           Utah        Vermont 
##              2              1              1              3              2 
##       Virginia     Washington  West Virginia      Wisconsin        Wyoming 
##              3              3              2              2              3 
## 
## Within cluster sum of squares by cluster:
## [1] 46.74796 11.95246 19.62285
##  (between_SS / total_SS =  60.0 %)
## 
## Available components:
## 
## [1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss"
## [6] "betweenss"    "size"         "iter"         "ifault"
```

---

# Clustering - Visualise clusters

We can visualise the clusters using the function `fviz_cluster`.


```r
fviz_cluster(kmeans, data = us_arrests_scaled)
```

![](machine_learning_slides_files/figure-html/unnamed-chunk-36-1.png)&lt;!-- --&gt;

---

# Clustering - Final step

And we can extract the clusters and add to our initial data to do some descriptive statistics at the cluster level:


```r
us_arrests %&gt;%
  mutate(cluster = kmeans$cluster) %&gt;%
  group_by(cluster) %&gt;%
  summarise_all("mean")
```

```
## # A tibble: 3 × 5
##   cluster Murder Assault UrbanPop  Rape
##     &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;
## 1       1  12.2    255.      68.4  29.2
## 2       2   3.6     78.5     52.1  12.2
## 3       3   5.84   142.      72.5  18.8
```

---

class: center, middle

# Principal Components Analysis

---

# Principal Components Analysis (PCA)

**Principal Components Analysis (PCA)** is an unsupervised machine learning technique that seeks to find *principal components*, i.e., linear combinations of the original predictors, that explain a large portion of the variation in a dataset.
- The goal of PCA is to explain most of the variability in a dataset with fewer variables than the original dataset.

For the example we will use the dataset `fat` available in the `faraway` library. The dataset contains 18 physical measurements.


```r
library(faraway)
attach(fat)
glimpse(fat)
```

```
## Rows: 252
## Columns: 18
## $ brozek  &lt;dbl&gt; 12.6, 6.9, 24.6, 10.9, 27.8, 20.6, 19.0, 12.8, 5.1, 12.0, 7.5,…
## $ siri    &lt;dbl&gt; 12.3, 6.1, 25.3, 10.4, 28.7, 20.9, 19.2, 12.4, 4.1, 11.7, 7.1,…
## $ density &lt;dbl&gt; 1.0708, 1.0853, 1.0414, 1.0751, 1.0340, 1.0502, 1.0549, 1.0704…
## $ age     &lt;int&gt; 23, 22, 22, 26, 24, 24, 26, 25, 25, 23, 26, 27, 32, 30, 35, 35…
## $ weight  &lt;dbl&gt; 154.25, 173.25, 154.00, 184.75, 184.25, 210.25, 181.00, 176.00…
## $ height  &lt;dbl&gt; 67.75, 72.25, 66.25, 72.25, 71.25, 74.75, 69.75, 72.50, 74.00,…
## $ adipos  &lt;dbl&gt; 23.7, 23.4, 24.7, 24.9, 25.6, 26.5, 26.2, 23.6, 24.6, 25.8, 23…
## $ free    &lt;dbl&gt; 134.9, 161.3, 116.0, 164.7, 133.1, 167.0, 146.6, 153.6, 181.3,…
## $ neck    &lt;dbl&gt; 36.2, 38.5, 34.0, 37.4, 34.4, 39.0, 36.4, 37.8, 38.1, 42.1, 38…
## $ chest   &lt;dbl&gt; 93.1, 93.6, 95.8, 101.8, 97.3, 104.5, 105.1, 99.6, 100.9, 99.6…
## $ abdom   &lt;dbl&gt; 85.2, 83.0, 87.9, 86.4, 100.0, 94.4, 90.7, 88.5, 82.5, 88.6, 8…
## $ hip     &lt;dbl&gt; 94.5, 98.7, 99.2, 101.2, 101.9, 107.8, 100.3, 97.1, 99.9, 104.…
## $ thigh   &lt;dbl&gt; 59.0, 58.7, 59.6, 60.1, 63.2, 66.0, 58.4, 60.0, 62.9, 63.1, 59…
## $ knee    &lt;dbl&gt; 37.3, 37.3, 38.9, 37.3, 42.2, 42.0, 38.3, 39.4, 38.3, 41.7, 39…
## $ ankle   &lt;dbl&gt; 21.9, 23.4, 24.0, 22.8, 24.0, 25.6, 22.9, 23.2, 23.8, 25.0, 25…
## $ biceps  &lt;dbl&gt; 32.0, 30.5, 28.8, 32.4, 32.2, 35.7, 31.9, 30.5, 35.9, 35.6, 32…
## $ forearm &lt;dbl&gt; 27.4, 28.9, 25.2, 29.4, 27.7, 30.6, 27.8, 29.0, 31.1, 30.0, 29…
## $ wrist   &lt;dbl&gt; 17.1, 18.2, 16.6, 18.2, 17.7, 18.8, 17.7, 18.8, 18.2, 19.2, 18…
```

---

# PCA - Preprocessing

PCA is **influenced** by the magnitude of each variable; therefore, the results obtained when we perform PCA will also depend on whether the variables have been individually scaled.


```r
apply(fat, 2, var)
```

```
##       brozek         siri      density          age       weight       height 
## 6.007576e+01 7.003582e+01 3.621955e-04 1.588114e+02 8.637227e+02 1.341651e+01 
##       adipos         free         neck        chest        abdom          hip 
## 1.330871e+01 3.323928e+02 5.909339e+00 7.107292e+01 1.162747e+02 5.132372e+01 
##        thigh         knee        ankle       biceps      forearm        wrist 
## 2.756200e+01 5.816801e+00 2.872664e+00 9.128095e+00 4.083193e+00 8.715808e-01
```

PCA works best with numerical data, so in case you have categorical features on the dataset, you need to "dummyfy" the features.

---

# PCA - Example

We can apply PCA with the function `prcomp`. You will also set two arguments, center and scale, to be TRUE. 


```r
fat_pca &lt;- prcomp(fat, center = TRUE, scale. = TRUE)
summary(fat_pca)
```

```
## Importance of components:
##                           PC1    PC2     PC3     PC4     PC5     PC6     PC7
## Standard deviation     3.2807 1.6586 1.04664 0.88222 0.81474 0.75617 0.56521
## Proportion of Variance 0.5979 0.1528 0.06086 0.04324 0.03688 0.03177 0.01775
## Cumulative Proportion  0.5979 0.7508 0.81163 0.85487 0.89175 0.92351 0.94126
##                            PC8     PC9    PC10    PC11    PC12    PC13    PC14
## Standard deviation     0.51350 0.48876 0.43012 0.36381 0.28051 0.24204 0.20448
## Proportion of Variance 0.01465 0.01327 0.01028 0.00735 0.00437 0.00325 0.00232
## Cumulative Proportion  0.95591 0.96918 0.97946 0.98681 0.99118 0.99444 0.99676
##                          PC15    PC16    PC17    PC18
## Standard deviation     0.1899 0.12595 0.07834 0.01527
## Proportion of Variance 0.0020 0.00088 0.00034 0.00001
## Cumulative Proportion  0.9988 0.99965 0.99999 1.00000
```

You obtain 18 principal components. Each of these explains a percentage of the total variation in the dataset. 
-  PC1 explains 59.8% of the total variance, which means that almost half of the information in the dataset can be encapsulated by just that one Principal Component. 
- PC2 explains 15% of the variance. With just PC1 and PC2 we can explain ~74% of the variance.

---

# PCA - Plotting

We can plot PCA using the `ggbiplot` library. We need to install this library from github using the function `install_github` from `devtools` giving the github link as parameter of the function.


```r
#devtools::install_github("vqv/ggbiplot")
library(ggbiplot)
ggbiplot(fat_pca)
```

![](machine_learning_slides_files/figure-html/unnamed-chunk-41-1.png)&lt;!-- --&gt;

---

# Reference

https://github.com/stedy/Machine-Learning-with-R-datasets/blob/master/insurance.csv

The Elements of Statistical Learning

Machine Learning: A Probabilistic Perspective
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
